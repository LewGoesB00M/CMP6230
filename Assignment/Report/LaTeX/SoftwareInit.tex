\section{Initial Software Setup}
This section details the configuration of the key software and packages within the pipeline. The installation 
processes of Miniconda and Docker are very lengthy and can therefore be found in Appendix A.

\subsection{VirtualBox \& Ubuntu}
The majority of data scientists utilise Linux distributions for their projects due to its open-source nature and the 
availability of many tools and packages. Therefore, VirtualBox, software to create a virtual machine which runs inside the host 
machine \autocite{oracle_oracle_nodate}, will be used to virtualise an Ubuntu 22.04 LTS system on the Windows host machine. This 
particular OS was chosen because of its relative recency and frequent software \& security updates. Virtual machines
also allow for "snapshots", which store the current state of the machine and its files at that time to be restored at any point in the 
event of unforeseen errors. Should a catastrophic error that would damage the system occur, the host machine would be unaffected as the 
virtual machine is isolated.

\begin{figure}[H]
    \centering
    \includegraphics[width=.5\linewidth]{Implementation/VBoxConfig.png}
    \caption{The configuration for the pipeline's VM.}
    \label{fig:VBoxConfig}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/Neofetch.png}
    \caption{The VM's Neofetch display.}
    \label{fig:Neofetch}
\end{figure}

\subsection{Conda environment and packages}
This section details the installation of packages to the Pipeline environment.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/Conda/CondaCreation.png}
    \caption{Creating the "Pipeline" Conda environment.}
    \label{fig:CondaCreation}
\end{figure}

\para Python 3.9.7 is used due to package compatibility issues with later versions of Python.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Conda/CondaPackages.png}
    \caption{Installing packages to the environment via Conda.}
    \label{fig:CondaPackages}
\end{figure}

\para Later in development, it was discovered that three packages that were necessary were not included 
in the original install command in Figure \ref{fig:CondaPackages}. They were installed at a later point and 
detailed in Figures \ref{fig:imbLearnInstall}, \ref{fig:AirflowGXInstall}, and \ref{fig:directRedisInstall}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Conda/ImbalancedLearn.png}
    \caption{Installing the imbalanced-learn package.}
    \label{fig:imbLearnInstall}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Conda/GXAirflow.png}
    \caption{Installing the airflow-provider-great-expectations package.}
    \label{fig:AirflowGXInstall}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Conda/DirectRedis.png}
    \caption{Installing the Direct-Redis package.}
    \label{fig:directRedisInstall}
\end{figure}

\para Direct-redis was installed via Pip, as it has not been uploaded to any Conda
channels, meaning Conda would be unable to install it.

\pagebreak 
\subsection{Docker and Docker images}
This section covers the downloading of the two necessary Docker images, MariaDB Columnstore and Redis. 
Their usage is further elaborated upon later in this chapter. The images for the containers will first need to be
downloaded from Docker's repository, shown in Figure \ref{fig:DockerPull}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Docker/Containers/Pull.png}
    \caption{Pulling the Docker images.}
    \label{fig:DockerPull}
\end{figure}

\pagebreak 
\subsubsection{MariaDB Columnstore}
MariaDB Columnstore runs on port 3306, but is mapped to port 3307 to avoid a possible Docker error.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Docker/Containers/MariaDB/1.png}
    \caption{Creating the MariaDB Columnstore container.}
    \label{fig:CreateMCS}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Docker/Containers/MariaDB/2.png}
    \caption{Creating the user account for MariaDB.}
    \label{fig:CreateMCSUser}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Docker/Containers/MariaDB/3.png}
    \caption{Creating the database for later use.}
    \label{fig:CreateDB}
\end{figure}

\pagebreak 
\subsubsection{Redis}
The Docker container for Redis, the in-memory data store, is hosted on port 6379 which is the default port used by 
the service \autocite{stream_security_security_nodate}.  

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Docker/Containers/Redis/1.png}
    \caption{Creating and accessing the Redis container.}
    \label{fig:CreateRedis}
\end{figure}


\subsection{Airflow and MLFlow initialisation}
Airflow and MLFlow do not immediately work upon install, and must first be initialised.

\subsubsection{Airflow}
Airflow's database of DAGs can be initialised through "airflow db init", which will create 
the default Airflow directory and database file.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/Initialisation/1.png}
    \caption{Initialising Airflow's database.}
    \label{fig:AirflowInit}
\end{figure}

Airflow allows for the creation of user accounts with allocated permission levels for the management of 
DAGs. Therefore, an administrative user was created for the purposes of this pipeline as depicted in Figures 
\ref{fig:AirflowUser1} and \ref{fig:AirflowUser2}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/Initialisation/2.png}
    \caption{Creating an administrative Airflow user.}
    \label{fig:AirflowUser1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/Initialisation/3.png}
    \caption{Verifying that the user was created.}
    \label{fig:AirflowUser2}
\end{figure}

After creating an admin user, the Airflow web server and task scheduler can be started. The web server provides 
an interface for reviewing DAGs, whereas the scheduler is the key backend component which executes each task within a 
DAG sequentially. Additionally, the scheduler will also automatically execute time-scheduled tasks such as those set to 
execute daily.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/Initialisation/4.png}
    \caption{Successfully starting Airflow's web server.}
    \label{fig:AirflowWebserver}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/Initialisation/5.png}
    \caption{Successfully starting Airflow's task scheduler.}
    \label{fig:AirflowScheduler}
\end{figure}

\subsubsection{MLFlow}
MLFlow will be used for the continuous monitoring and storage of the produced models. 
After installing it with Conda as depicted in Figure \ref{fig:CondaPackages}, it must then 
be initialised. This is performed by creating a dedicated directory for the service and then 
creating its server.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Initialisation/1.png}
    \caption{Creating a directory for MLFlow and initialising its database.}
    \label{fig:MLFlowInit}
\end{figure}

\para To do so, the Pipeline environment must be active for MLFlow to be recognised. Then the server 
is established, setting its backend storage database as an SQLite database titled "mlflow.db",
its artifact (model) storage location as the "artifacts" subfolder, and setting the host IP as 0.0.0.0. By using 
this IP rather than localhost, it allows for applications inside containers (i.e. Airflow, Redis) to communicate 
with MLFlow when they otherwise would be unable to due to their containerisation. The database file and "artifacts"
subfolder were also created by MLFlow upon execution of the command as they did not exist at the time. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Initialisation/3.png}
    \caption{Running MLFlow's frontend web UI.}
    \label{fig:MLFlowUICmd}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Initialisation/2.png}
    \caption{MLFlow's web UI from a fresh installation.}
    \label{fig:MLFlowEmptyUI}
\end{figure}

\para The MLFlow web interface can be accessed by simply running "mlflow ui" as depicted in Figure \ref{fig:MLFlowUICmd}
and then navigating to localhost:5000 in a web browser. At present, there are no experiments or models as the software 
was freshly installed and initialised.

\subsection{Great Expectations}
Great Expectations (GX) is used for validating the dataset. It allows for the automatic processing of 
the data against rules that can be set. GX cannot be used immediately after install, and has some initialisation 
steps detailed in Figures \ref{fig:GXVersion} through \ref{fig:GXCheckpoint2}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/1.png}
    \caption{Checking the installed GX version and initialising it.}
    \label{fig:GXVersion}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/2.png}
    \caption{Confirmation of the successful initialisation.}
    \label{fig:GXInitConfirm}
\end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/3.png}
%     \caption{Viewing the contents of the created directory.}
%     \label{fig:GXDir}
% \end{figure}

\para This pipeline uses GX version 0.18.15 as seen previously in Figure \ref{fig:GXVersion},
meaning it supports their new fluent configuration. However, this will not be necessary,
and the data source can be created from the CLI.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/4.png}
    \caption{Creating a new data source (1/3)}
    \label{fig:GXDatasource1}
\end{figure}

\para Upon the initial creation of the data source, GX automatically opens a Jupyter notebook for its 
configuration, depicted below in Figure \ref{fig:GXDatasource2}. Part of the creation process 
involves naming the data source, and therefore "LoanApproval\_DataSource" was used as the name.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/5.png}
    \caption{Creating a new data source (2/3)}
    \label{fig:GXDatasource2}
\end{figure}

\para Towards the end of the configuration notebook, there is a block containing two functions, where the first 
will ensure that the configuration is sanitised and valid where it is then saved, and the second is to output the created 
data source's properties to ensure they match what was expected.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/6.png}
    \caption{Creating a new data source (3/3)}
    \label{fig:GXDatasource3}
\end{figure}

\para The output text matched what was expected of the data source, meaning that the data source is finalised
and ready to use. Next, a "suite" must be created to allow for the easy creation of expectations \autocite{gx_expectation_nodate}.
The creation process is similar to that of the data source, where the command is executed, and configuration details are confirmed in 
a Jupyter notebook as depicted in Figure \ref{fig:GXSuite2}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/GX/Initialisation/7.png}
    \caption{Creating a new suite (1/2)}
    \label{fig:GXSuite1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/GX/Initialisation/8.png}
    \caption{Creating a new suite (2/2). The full list of expectations is in Table \ref{tab:Expectations}.}
    \label{fig:GXSuite2}
\end{figure}

\begin{longtable}{ | p{0.4\textwidth} | p{0.5\textwidth} |}
    \hline
    \cellcolor{blue!25}Item & \cellcolor{blue!25}Expectation\\
    \hline
    Dataset & Must be exactly 14 columns. \\
    \hline
    loan\_status & Must not be null. \newline Must be 0 or 1. \\
    \hline 
    person\_gender & Must be 'female' or 'male'. \\
    \hline 
    person\_education & Must be 'Bachelor', 'Associate', 'High School', 'Master', or 'Doctorate'. \\
    \hline
    person\_home\_ownership & Must be 'RENT', 'MORTGAGE', 'OWN', or 'OTHER'.\\
    \hline 
    loan\_intent & Must be 'EDUCATION', 'MEDICAL', 'VENTURE', 'PERSONAL', 'DEBTCONSOLIDATION', or 'HOMEIMPROVEMENT'.\\
    \hline 
    previous\_loan\_defaults\_on\_file & Must be 'Yes' or 'No'. \\
    \hline
    credit\_score & Must be between 350 and 900. \\
    \hline
    cb\_person\_cred\_hist\_length & Must be between 0 and 30. \\
    \hline
    loan\_percent\_income & Must be between 0 and 0.8. \\
    \hline
    loan\_int\_rate & Must be between 5.0 and 30.0. \\
    \hline
    loan\_amnt & Must be between 0 and 50,000. \\
    \hline 
    person\_emp\_exp & Must be between 0 and 125. \\
    \hline 
    person\_income & Must be greater than 5000. \\
    \hline 
    person\_age & Must be greater than 0. \\
    \hline
\caption{Expectations set for the dataset and its columns.}\label{tab:Expectations}
\end{longtable}

\para After the suite's creation, GX then allows for the creation of checkpoints, which save the expectations and allow
them to be applied to any dataset, which would be useful when the dataset is updated, as there would be no need 
to create a new suite of expectations.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/GX/Initialisation/9.png}
    \caption{Creating the checkpoint based on the suite.}
    \label{fig:GXCheckpoint1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/GX/Initialisation/10.png}
    \caption{Saving the checkpoint in the prompted Jupyter notebook.}
    \label{fig:GXCheckpoint2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/GX/Initialisation/11.png}
    \caption{Confirming the existence of the checkpoint YAML file.}
    \label{fig:GXCheckpoint3}
\end{figure}
% Possibly unneeded. If used, 10.png would need to be cropped but that's hard to do without removing key info
% as the key info is actually at the bottom of the image.
