% -------------------------------------------------------------------------------
% Establish page structure & font.
\documentclass[12pt]{report}

\usepackage[total={6.5in, 9in},
	left=1in,
	right=1in,
	top=1in,
	bottom=1in,]{geometry} % Page structure

\usepackage{graphicx} % Required for inserting images
\graphicspath{{../../.images/}} % Any additional images I use (BCU logo, etc) are from here.

\usepackage[utf8]{inputenc} % UTF-8 encoding
\usepackage[T1]{fontenc} % T1 font
\usepackage{float}  % Allows for floats to be positioned using [H], which correctly
                    % positions them relative to their location within my LaTeX code.
\usepackage{subcaption}

% -------------------------------------------------------------------------------
% Declare biblatex with custom Harvard BCU styling for referencing.
\usepackage[
    useprefix=true,
    maxcitenames=3,
    maxbibnames=99,
    style=authoryear,
    dashed=false, 
    natbib=true,
    url=false,
    backend=biber
]{biblatex}

\usepackage[british]{babel}

% Additional styling options to ensure Harvard referencing format.
\renewbibmacro*{volume+number+eid}{
    \printfield{volume}
    \setunit*{\addnbspace}
    \printfield{number}
    \setunit{\addcomma\space}
    \printfield{eid}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

% Declaring both bib sources.
% Pipeline is the original one copied from draft pipeline, Report is new for this.
% This is because pipeline.bib is over a thousand lines long.
\addbibresource{Pipeline.bib}
\addbibresource{Report.bib}

% -------------------------------------------------------------------------------
% To prevent "Chapter N" display for each chapter
\usepackage[compact]{titlesec}
\usepackage{wasysym}
\usepackage{import}

\titlespacing*{\chapter}{0pt}{-2cm}{0.5cm}
\titleformat{\chapter}[display]
{\normalfont\bfseries}{}{0pt}{\Huge}

% -------------------------------------------------------------------------------
% Custom macro to make an un-numbered footnote.

\newcommand\blfootnote[1]{
    \begingroup
    \renewcommand\thefootnote{}\footnote{#1}
    \addtocounter{footnote}{-1}
    \endgroup
}

% -------------------------------------------------------------------------------
% Fancy headers; used to show my name, BCU logo and current chapter for the page.
\usepackage{fancyhdr}
\usepackage{calc}
\pagestyle{fancy}

\setlength\headheight{37pt} % Set custom header height to fit the image.

\renewcommand{\chaptermark}[1]{%
    \markboth{#1}{}} % Include chapter name.


% Lewis Higgins - ID 22133848           [BCU LOGO]                [CHAPTER NAME]
\lhead{Lewis Higgins - ID 22133848~~~~~~~~~~~~~~~\includegraphics[width=1.75cm]{BCU}}
\fancyhead[R]{\leftmark}

% ------------------------------------------------------------------------------
% Used to add PDF hyperlinks for figures and the contents page.

\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=black,
}

% ------------------------------------------------------------------------------
\usepackage{xcolor} 
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{amssymb}
% ------------------------------------------------------------------------------
\usepackage{tcolorbox}
\newcommand{\para}{\vspace{7pt}\noindent}
% -------------------------------------------------------------------------------

\title{Data Management and MLOps Activities Log Report}
\author{Lewis Higgins - Student ID 22133848}
\date{December 2024}

% -------------------------------------------------------------------------------

\begin{document}


\makeatletter
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.7\linewidth]{BCU}\\[4ex]
        {\huge \bfseries CMP6230 - Assignment 2}\\[2ex]
        {\large \bfseries  \@title}\\[50ex]
        {\@author}\\[2ex]
        {CMP6230 - Data Management and Machine Learning Operations}\\[2ex]
        {Module Coordinator: Sima Iranmanesh}\\[10ex]
    \end{center}
\end{titlepage}
\makeatother
\thispagestyle{empty}
\newpage


% Page counter trick so that the contents page doesn't increment it.
\setcounter{page}{0}

\tableofcontents
\thispagestyle{empty}

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
This report covers the planning and implementation of a five-stage Machine Learning Operations pipeline, from the initial 
data ingestion to the monitoring of the produced model, beginning 
with the identification of three candidate datasets for the pipeline to be conducted with, and continuing 
into descriptions of what each stage of the pipeline consists of, and how it will be implemented with the
one chosen dataset using a wide variety of software that is also used within industry. The implementation 
based on the plan produces a fully operational Machine Learning Operations (MLOps) pipeline, with a deployed model 
that can be used to make predictions via a REST API hosted on a Uvicorn server.

% Importing the sections from the original report here.
\include{Datasets.tex}
\include{PipelineStages.tex}


\chapter{Evaluation and communication of wider issues}
There are many risks and concerns regarding data handling and processing in general that must be accounted 
for as part of the development of any MLOps pipeline. These come in the form of ethical and legal considerations
such as the risks pertaining to the use of public datasets on sites like Kaggle, as well as significant legal 
boundaries posed by data protection legislation. Additionally, there are issues concerning machine learning models 
in general, namely the key issue of model drift over time. This chapter of the report will define and explain each 
of these wider issues and how this pipeline addresses them where necessary.

\section{Dataset availability}
The dataset was shared under an Apache 2.0 open-source licence, permitting access and modification with no restrictions
except crediting the original author \autocite{apache_apache_nodate}, meaning that there are not any ethical or legal 
considerations of note with this dataset's usage. Given that the chosen dataset also consists of synthetic data,
there are fewer necessary considerations for its use.

\section{Using synthetic data}
\subsection{What is synthetic data?}
This term has been frequently used throughout the report to describe the Loan Approval Classification Dataset, and refers to 
data that has been generated algorithmically rather than collected from a real source. However, the generation of the 
synthetic data does often depend on real data to identify patterns and trends, meaning that legislation such as GDPR is still relevant
in those scenarios because the generated data must be impossible to link back to the original subject \autocite{Lopez2022OnTL}.

\subsection{How is synthetic data generated?}
An example of a synthetic data generation method is the Synthetic Minority Oversampling Technique, also known as SMOTE, which was used
in the generation of the loan dataset \autocite{zoppelleto_financial_nodate}, which creates synthetic data in a dataset based on the
other rows as previously mentioned in Section \ref{sec:Dataset}. It does this using the K-Nearest Neighbours algorithm to generate 
data points based on the averages across other similar points. SMOTE will also be used in Section \ref{sec:ImpPreprocessing} to balance
the dataset by oversampling the minority class (approved loans), as it was discovered in Figure \ref{fig:Bar6} that there are considerably 
more rejected loans than approved loans in this dataset.

\section{Model drift}
Model drift is a phenomenon that affects deployed production machine learning models where changes in 
their environment over time affects their performance \autocite{nigenda_amazon_2022}. Model drift is not an 
immediate occurrence, and can take a long time to occur, emphasising the importance of continuous model evaluation. 
Table \ref{tab:Drift} details the two primary kinds of model drift.

\pagebreak

\begin{longtable}{ | p{0.2\textwidth} | p{0.4\textwidth} | p{0.3\textwidth} |}
    \hline
    \cellcolor{blue!25}Drift type & \cellcolor{blue!25}Description & \cellcolor{blue!25}Dataset example\\
    \hline
    Data drift & Changes in the distributions of the ingested data over time that eventually significantly differ from the model's training data \autocite{datacamp_understanding_nodate}.
    & In this dataset, interest rates and people's yearly income may change as time passes or economic inflation occurs.\\
    \hline
    Concept drift & Changes in the relationship between the input and target variables \autocite{nigenda_amazon_2022}. 
    & In this dataset, this is somewhat unlikely. However, it could occur if there is a significant housing or job market crash 
    that would cause more people to need loans, which would change the original relationships between the variables.\\
    \hline
\caption{The common types of model drift.}\label{tab:Drift}
\end{longtable}

\para Model drift can be a significant issue that greatly impacts the performance of ML models if it is not quickly noticed, and can 
also be an ethical concern if the model is being used to influence decisions such as granting loans in this project. 
Therefore, combatting model drift through methods such as continuous monitoring is necessary to ensure that the model remains accurate 
and usable. This will be accomplished in this project through continuous monitoring via MLFlow's monitoring dashboard.

\section{Data handling}
This project must then also take into account four key elements of data handling - these being data privacy, security, 
ethics and data protection laws. 

\begin{longtable}{ | p{0.2\textwidth} | p{0.7\textwidth} |}
    \hline
    \cellcolor{blue!25}Term & \cellcolor{blue!25}Description\\
    \hline
    Data privacy & An individual's ability to govern what happens to their personal data \autocite{cloudflare_what_nodate}. Personal data 
    refers to data that could be used to singularly identify someone \autocite{yang_big_2021}.\\
    \hline
    Data security & The protection of personal/sensitive information from unauthorized access, use or manipulation \autocite{ibm_security_2021}.
    This can be the physical protection of material such as hard drives, and software protections like encryption. \\
    \hline
    Data ethics & A blanket term encompassing the moral obligations of data collection, use and protection \autocite{harvard_business_school_5_2021}.
    Ethical data storage would mean that the data subjects willingly gave their data and can ask for its deletion at any point. 
    Mandated by data protection legislation. \\
    \hline 
    Big data ethics & The application of data ethics to massive datasets, concerning the implications of their collection and use on society as a whole
    \autocite{richards_big_2014}. \\
    \hline 
    General Data \newline Protection \newline Regulations (GDPR) & Legislation introduced in the EU in 2016, giving individuals significantly more 
    rights over their personal data. Data subjects most notably may request a copy of their data, the removal of their data, and to object to their data's 
    collection \autocite{ico_guide_2024}. Additionally, data must be kept secure using all available means. Companies who fail to adhere to these policies
    face significant sanctions of \euro10,000,000 or 2\% of the company's annual turnover for minor violations, or double this (\euro20,000,000, 4\% turnover)
    for major violations, whichever figure is higher. \\
    \hline
    Data Protection Act 2018 & When the UK left the EU, the GDPR no longer applied. Therefore, the UK adopted the GDPR as an amendment to its own
    Data Protection Act. There are minimal differences between the two, only that the UK's fines are in GBP rather than Euros, meaning fines go up 
    to \pounds17,500,000 or 4\% turnover \autocite{ico_enforcement_2024}. \\
    \hline
\caption{A brief overview of relevant data terminology.}\label{tab:dataTerms}
% Maybe it shouldn't be "brief". I think GDPR especially needs its own paragraph moreso than a table column.
\end{longtable}

\noindent Because the dataset used in this pipeline consists of entirely synthetic data, very few of these data handling concerns apply. 
However, the ethics of synthetic data generation can be called into question as there are few details on the dataset's Kaggle 
page describing the source used for the generation of this data, and whether the real people that this data was created based 
on are aware of this and consented to it. Aside from this, there are no further concerns as data privacy and GDPR are not 
relevant given that the data used to train the model is not real.


% Example 2 (SimonRoadknight) is 21,334 words, or 18,809 without its appendices and references.
% Example 3 (MihaiValentin) is 12,802 words.

\include{SoftwareInit}

\section{Package imports}
Many packages need to be imported for the Airflow DAG of the pipeline to succeed. These can be found 
below, alongside descriptions in the form of Python comments, in Figures \ref{fig:PipelineDAGImports} and 
\ref{fig:PipelineFunctionsImports}. The use of these packages within pipeline functions is detailed 
in this report within the appropriate pipeline stage.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineDAGImports.png}
    \caption{The packages necessary to run the DAG itself.}
    \label{fig:PipelineDAGImports}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctionsImport.png}
    \caption{The packages necessary to run the functions within each DAG.}
    \label{fig:PipelineFunctionsImports}
\end{figure}

\section{Data Ingestion}\label{sec:ImpIngestion}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Ingestion.png}
    \caption{The code for the entire Ingestion stage.}
    \label{fig:IngestionCode}
\end{figure}

\para This code is split across four functions that are called upon within the main 
ETL function. The ETL function will call on extract\_csv to read the dataset CSV from 
the path set as DEFAULT\_PATH. After this, some data type transformations are performed 
to ensure the optimal data types are used for each column. Finally, the transformed 
DataFrame is written to the MariaDB Columnstore instance hosted in the Docker 
container at port 3306.

\para For data validation,
Conda was used to install a helper package for Airflow that adds the Great Expectations Operator.
This operator connects to the checkpoint produced in Figure \ref{fig:GXCheckpoint3} to run the saved validation 
methods on the ingested dataset without the need to declare it as a specialised Python function within 
the code. Through the use of Great Expectations, it can be confirmed that the ingested data does not differ 
from the original data and maintains its integrity.

\section{Data Preprocessing}\label{sec:ImpPreprocessing}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Preprocessing1.png}
    \caption{The secondary functions used in the main Preprocessing function.}
    \label{fig:PreprocessingCode1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Preprocessing2.png}
    \caption{The code for the main Preprocessing function.}
    \label{fig:PreprocessingCode2}
\end{figure}

\para This code forms the Data Preprocessing stage of the pipeline. Data is retrieved from the 
Columnstore and considerable outliers are removed, primarily from the Age and Income columns, 
where data can be outright false or differs enough to heavily skew the dataset and affect scaling.
After this, categorical data is encoded using label encoding and one-hot encoding where necessary.
The data is then balanced using SMOTE to resolve the significant imbalance between granted and denied loans 
before being split into training and testing sets, which are serialized and saved into Redis. The use of 
a DirectRedis connection rather than a standard Redis connection removes the need for explicit serialization, 
as it is automatically performed when "r.set()" is called. 

\section{Model Development}\label{sec:ImpDevelopment}
Internally, this section was referred to as "Training", seen in the function name and associated 
DAG task.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Training.png}
    \caption{The code for the Training function.}
    \label{fig:TrainingCode}
\end{figure}

The Training function deserializes and reads the preprocessed DataFrame from Redis via a Direct-Redis 
connection, and then scales the data using a StandardScaler from Scikit-Learn. MLFlow is started 
to begin its tracking of the model, and then the model is instantiated and trained on the preprocessed data 
using the parameters provided to the Training function. These parameters would be provided within the DAG code.
The model is then serialized using Pickle and stored into Redis, alongside the parameters for logging purposes 
and the MLFlow run ID so that the run can be resumed in the Evaluation phase.


\section{Model Evaluation}\label{sec:ImpEvaluation}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Evaluation1.png}
    \caption{eval\_metrics, which returns the evaluation metrics of a model.}
    \label{fig:Evaluation1}
\end{figure}

\para The eval\_metrics function calculates the accuracy, precision and F1 scores of the trained model 
using predefined functions that are part of Scikit-Learn. This is later used in the main Evaluation function 
to log these scores in MLFlow.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Evaluation2.png}
    \caption{The main Evaluation function.}
    \label{fig:Evaluation2}
\end{figure}

\para The Evaluation function retrieves the serialized model, parameters and run ID from Redis 
via a Direct-Redis connection, deserializing the model with Pickle. The testing dataset is 
retrieved and the MLFlow run is resumed to then make predictions using the model. Using the 
eval\_metrics function, the metrics obtained are output to the console (viewable via the DAG's logs page)
and also logged in the MLFlow run. The model is then saved and the MLFlow is ended, completing the pipeline.

\para MLFlow runs are all saved to the MLFlow server running on port 5000. By accessing the server through 
a web browser at localhost:5000, the dashboard can be accessed as seen in Figure \ref{fig:MLFlowDash}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Other/1.png}
    \caption{The MLFlow dashboard, showing the first produced model.}
    \label{fig:MLFlowDash}
\end{figure}

\para The first produced model can be seen on the dashboard. By going into its page, its metrics and 
parameters that were stored as part of the Evaluation function can be viewed as seen in Figure \ref{fig:MLFlowModel}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Other/2.png}
    \caption{The first model's metrics and parameters.}
    \label{fig:MLFlowModel}
\end{figure}



\section{Completed Airflow DAGs}\label{sec:CompletedDAGs}
Two DAGs were created as part of the pipeline. "DockerContainers" consists of two BashOperators 
to start the two Docker containers for MariaDB Columnstore and Redis, whereas "MLOpsPipeline" 
consists of the five tasks of the pipeline. Figure \ref{fig:DAGsList} shows the list of DAGs, 
containing only these two\footnote{Normally, Airflow includes a large list of examples, though these were 
removed by changing the configuration file located at \texttildelow/airflow/airflow.cfg.} DAGs.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/DAGs/1.png}
    \caption{The list of DAGs in Airflow.}
    \label{fig:DAGsList}
\end{figure}

Figure \ref{fig:PipelineGraphDAG} shows the completed Airflow DAG's graph view, which is a graphical 
representation of the sequence of tasks. The five tasks of the pipeline are shown, 
though deployment is not one of them, which is further explained in Section \ref{sec:ImpDeployment}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/DAGs/PipelineGraph.png}
    \caption{The graph view of the completed MLOpsPipeline DAG.}
    \label{fig:PipelineGraphDAG}
\end{figure}

The code for the completed DAG consists of four PythonOperators, each to call the respective main 
function of each stage as detailed in their respective section, as well as a GreatExpectationsOperator 
to run data validation between ingestion and preprocessing. It also declares some variables that are passed 
to each function, which can be easily modified.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineDAG.png}
    \caption{The complete code of the MLOpsPipeline DAG.}
    \label{fig:PipelineDAGCode}
\end{figure}

\section{Model Deployment}\label{sec:ImpDeployment}
Deployment is performed separately from the rest of the stages in this pipeline, 
as it involves the hosting of a Uvicorn server on port 8000 to run the code written 
in the Model API script using FastAPI. Through running the server using the command 
"uvicorn modelAPI:main --reload" as detailed in Figure 
\ref{fig:UviStartup}, the "docs" page of FastAPI's own Swagger API can be accessed to manually perform POST 
requests to get predictions from the model. The "--reload" argument means that whenever the 
modelAPI Python file is updated, the server will automatically update it with the changes.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/Startup.png}
    \caption{Starting the Uvicorn server on port 8000.}
    \label{fig:UviStartup}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/LoadModel.png}
    \caption{Loading the pickled model to make predictions with.}
    \label{fig:UviLoadModel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.5\linewidth]{Implementation/FastAPI+Uvi/InputAndPrediction.png}
    \caption{The FastAPI classes used for input and predictions.}
    \label{fig:UviClasses}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/Code.png}
    \caption{The FastAPI endpoints for getting model predictions.}
    \label{fig:UviCode}
\end{figure}

\para The docs page generated from these endpoints is shown below in Figure \ref{fig:UviDocs}.
Using this page, inputs can be given to the model by making a POST request to its endpoint, 
which will return a prediction.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/DocsPage.png}
    \caption{The docs page for the model-API script.}
    \label{fig:UviDocs}
\end{figure}

\para POST requests can be made by clicking on the endpoint "/loan/predict/single",
followed by "Try it out" and then entering data for each row. The model will then 
interpret the data for each column and make a prediction based upon it. To test this, 
two predictions were given to the model, where one is a loan that would be rejected (Figure \ref{fig:UviTrueNegative})
and the other is a loan that would be granted (Figure \ref{fig:UviTruePositive}). 

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/TrueNegative.png}
    \caption{The response for a loan that would be rejected (loan\_status of 0).}
    \label{fig:UviTrueNegative}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/TruePositive.png}
    \caption{The response for a loan that would be granted (loan\_status of 1).}
    \label{fig:UviTruePositive}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/TruePredictionsCLI.png}
    \caption{The command-line outputs of both POST requests.}
    \label{fig:UviCLI}
\end{figure}

\para Both of these inputs can be confirmed to be correctly predicted as they were actually two 
rows from the testing split of the dataset, which the model was not trained upon.

\section{Changes over time}
During the implementation of the pipeline, the initial package used for serializing data was PyArrow.
However, as development continued, it was discovered that many of PyArrow's useful functions are now 
deprecated, and have been since 2021. This made serializing data and passing it between DAG stages considerably more difficult, 
and for this reason an alternative package was identified: Direct-Redis. Direct-Redis builds on top of the Redis 
package, but will instantly serialize and deserialize data when set() or get() is called, greatly expediting 
the process of storing data in and retrieving data from Redis stores \autocite{direct-redis_direct-redis_nodate}.
This resolved the serialization issue, meaning the pipeline worked smoothly without any errors, and also 
resulted in much cleaner and easily-readable code. An additional alternative would have been to 
use Pickle for all serialization rather than just that of the model, which would have been functionally identical.

\para Additionally, after the original draft pipeline was created, some inefficiencies were noted across the preprocessing and deployment 
stages which were later addressed.

\subsection{Preprocessing}
The encoding of the data colossally increased the dimensionality of the dataset as a by-product of one-hot encoding.
This could have been slightly reduced by instead using label encoding on the previous loan defaults column, as one-hot encoding 
created unnecessary columns for "Yes" and "No", though only one of these could ever be true at a time, meaning a simple 1 or 0
in a single column would suffice. This is shown below in Figure \ref{fig:PreprocessingCode1NEW}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/NewEncoding.png}
    \caption{The updated Encode function, which uses label encoding for previous loan defaults.}
    \label{fig:PreprocessingCode1NEW}
\end{figure}

\noindent Part of the encode function uses a new function titled "serialize\_to\_file". This function, depicted in Figure \ref{fig:SerializeToFile},
was added to assist with the model's updated deployment which will be further elaborated upon in Section \ref{subsec:NewDeployment}. 
The function will take an object (obj) and string (file\_name) as parameters, and then serialize the object with Pickle and save it to a file
in the "home/lewis/CMP6230" directory with a name dictated by the string.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/SerializeToFile.png}
    \caption{The "serialize\_to\_file" function, which serializes and saves an object to a file.}
    \label{fig:SerializeToFile}
\end{figure}

\noindent This was also used to serialize the StandardScaler after fitting it to the training data.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/ScalerSerialize.png}
    \caption{Using serialize\_to\_file to serialize the fitted StandardScaler.}
    \label{fig:SerializeScaler}
\end{figure}

\subsection{Deployment}\label{subsec:NewDeployment}

There were also some major issues regarding the model's deployment and accessing predictions for the model. Figure \ref{fig:UviClasses} 
depicts how twenty-three columns originally had to be entered prior to receiving a prediction. This was due to the one-hot encoding 
used on the dataset, though the encoding can instead be performed within the ModelAPI script itself so that the user only needs to
enter the original 13 columns of the dataset\footnote{This introduced some further complications which were suitably addressed in Figure \ref{fig:UviOneHot}}. 
Furthermore, the deployment issues were not restricted to just the user's input; the data being fed to the model was not scaled,
which could have led to wildly incorrect predictions. This was remedied with the "serialize\_to\_file" function depicted previously in 
Figure \ref{fig:SerializeToFile}, and then deserialising it from this file in the ModelAPI script.

\para These issues caused a total rewrite of the ModelAPI script, beginning with the LoanInput class. The new version of 
this class uses only the rows originally found in the dataset, as the encoding is now handled internally by the script.
This results in the user only needing to enter data for the original 13 features\footnote{They do not need to enter the loan status, as that is what the model aims to predict.}
compared to the 23 of the original implementation.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/NewLoanInput.png}
    \caption{The updated LoanInput class that needs 10 less inputs than the original.}
    \label{fig:NewLoanInput}
\end{figure}

\noindent As previously depicted in Figures \ref{fig:PreprocessingCode1NEW} and \ref{fig:SerializeScaler}, this rewrite influenced changes in 
the preprocessing stage to ensure that the same encoders and scalers fitted to the dataset were saved to files for use on inputs to the model.
After these changes were made, the ModelAPI script was updated to load the encoders and scaler from the serialized files with Pickle.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/LoadFiles.png}
    \caption{Loading the LabelEncoders and StandardScaler from their serialized files.}
    \label{fig:UviLoadFiles}
\end{figure}

\noindent Once these were loaded and deserialized by Pickle, they were used for encoding and scaling the data input by the user.
The LabelEncoders were very simple to apply to the user's input, seen in Figure \ref{fig:UviLabelEncoding} as they had already 
been fitted to the expected values for the education and previous default columns when the model was trained.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/NewUviEncoding1.png}
    \caption{Label encoding the education and previous default columns.}
    \label{fig:UviLabelEncoding}
\end{figure}

\pagebreak 
\noindent However, one-hot encoding was far more challenging. Pandas' "get\_dummies" function would work differently to how 
it did when the dataset was preprocessed, as the dataset contained a wide variety of values for dummy columns to be created from,
but the user's input is a single row. This was remedied by creating a list of the expected dummy columns and adding them to the user's 
input, setting their values to 0 if they didn't already exist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/NewUviEncoding2.png}
    \caption{Manually one-hot encoding the user's input.}
    \label{fig:UviOneHot}
\end{figure}

\noindent After this, the input row needed to be scaled, as it was not scaled in the original pipeline implementation.
This introduced a further complication in that the columns must be in the exact order that they were when the scaler was fitted,
which the manual one-hot encoding could not guarantee. To fix this, the features in the input row were rearranged to be how the scaler 
expected them to be.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/DFRearrangeScale.png}
    \caption{Rearranging the dataframe to scale the user's input.}
    \label{fig:DFRearrangeScale}
\end{figure}

\noindent Finally, the encoded and scaled input row can be used to make a prediction by converting it to a NumPy array, which 
Pandas has the convenient function "to\_numpy" for, and feeding it into the model. Then, the prediction is output to the 
backend console interface and is returned in response to the overall POST request.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/NewUviPredict.png}
    \caption{Converting the input row to a NumPy array and predicting with the model.}
    \label{fig:NewUviPredict}
\end{figure}

\noindent The predictions made after these changes can be found in Figures \ref{fig:TruePositiveNew} and \ref{fig:TrueNegativeNew}. 
They can be confirmed to be correct as they are rows taken from the testing set, meaning that the model had not previously seen them. 
Specifically, they are row 1388 (Positive / Granted loan) and row 6736 (Negative / Denied loan) of the dataset.
The row numbers differ heavily because train\_test\_split shuffles the dataset as previously discussed.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/JAN 10 UPDATES/NewTruePositiveOutput.png}
    \caption{A true positive prediction made after the ModelAPI changes.}
    \label{fig:TruePositiveNew}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/JAN 10 UPDATES/NewTrueNegativeOutput.png}
    \caption{A true negative prediction made after the ModelAPI changes.}
    \label{fig:TrueNegativeNew}
\end{figure}

\noindent For testing purposes, the row used in Figure \ref{fig:TrueNegativeNew} was modified to have no previous loan 
defaults, as it is known from the thorough data analysis in Section \ref{subsec:EDA} that this is the most influential 
factor. Originally, this applicant had defaulted on a loan before, which caused their application to be rejected. However,
after changing this to indicate they had not defaulted before, the loan was approved by the model as depicted in Figure 
\ref{fig:UviCustomRow}.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/JAN 10 UPDATES/UviCustomRow.png}
    \caption{The different prediction after modifying the input row in Figure \ref{fig:TrueNegativeNew}.}
    \label{fig:UviCustomRow}
\end{figure}

\subsection{Differences from plans to final implementation}
There were some ideas originally considered in the initial and final plans that were found to be unsuitable in implementation.

\subsubsection{Initial plan}
The original intended package intended for serializing data was Apache's
PyArrow \autocite{apache_streaming_nodate}. However, as development of the pipeline continued, it was discovered that many of PyArrow's
useful functions are now deprecated, and have been since 2021. This made serializing data
and passing it between DAG stages considerably more difficult, and for this reason an alternative
package was identified: Direct-Redis. Direct-Redis builds on top of the Redis package,
but will instantly serialize and deserialize data when set() or get() is called, greatly expediting
the process of storing data in and retrieving data from Redis stores \autocite{direct-redis_direct-redis_nodate}. 
This resolved the serialization issue, meaning the pipeline worked smoothly without
any errors, and also resulted in much cleaner and easily-readable code, despite differing 
substantially from the initial plan.

\subsubsection{Final plan}
Part of the final plan was to initialise the MLFlow server as part of the DockerContainers DAG previously 
mentioned in Section \ref{sec:CompletedDAGs}. However, research into this indicated that this would be poor 
practice, as DAGs should not be used to host continuous services \autocite{apache_architecture_nodate} like MLFlow's 
backend server, as the DAG would be permanently stuck in a "running" state. This same concept applied to another 
idea in the final plan, which was to host the Uvicorn server for the deployed model's REST API within a DAG, 
though this also was not done for the same reason.


\section{Potential for future improvements}
Overall, the produced pipeline is successful from start to finish as a seamless Airflow DAG. However, there is room 
for potential future improvements, primarily in relation to the deployed model's security. This is because it is 
important to note that the use of the Swagger API provided by FastAPI (the "docs" page) is not suitable for an actual production 
environment, as it can be manipulated by threat actors to possibly give them direct unauthorized access to the 
server's backend, meaning it is normally disabled. An actual production environment would link their 
model to their actual web page with forms and text entry fields to input data, though this would not 
have been feasible for this particular project due to time constraints as well as not owning a domain 
to host the site on, meaning it is restricted to only localhost. An alternative option would be to password-protect 
the Swagger API docs page \autocite{ray_securing_2023}, preventing access to those without the necessary credentials.

\para Additionally, the source code for the pipeline also contains the credentials used to access the Columnstore 
and Redis containers, which could potentially be used maliciously by a threat actor to steal data from or upload malicious 
data to either service. This could be remedied through system environment variables, which could store the credentials outside 
the code and then use them in real time as the code is executed \autocite{freecodecamp_python_2023}.  




\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

The implementation of this MLOps pipeline for loan approval classification demonstrates the successful integration of various
data management and machine learning technologies to create an automated, reproducible workflow. By leveraging tools such as Docker,
Airflow, MLflow, and FastAPI, the pipeline effectively handles data ingestion, preprocessing, model development, evaluation, and 
deployment. Key achievements of this pipeline include:

\begin{itemize}
    \item Efficient data ingestion to an OLTP MariaDB Columnstore database.
    \item Data validation using Great Expectations.
    \item Robust preprocessing techniques, including outlier removal and data balancing with SMOTE.
    \item Automated Random Forest classification model training and evaluation.
    \item Continuous model tracking and versioning with MLflow.
    \item Deployment of the model as a REST API using FastAPI and Uvicorn.
\end{itemize}

\noindent The pipeline's modular structure allows for easy maintenance and scalability, as demonstrated by the changes and improvements 
made after the original draft completion of the pipeline. This therefore could enable future enhancements such as the addition 
of other classification models such as Linear or Logistic Regression in order to find the most accurate model to make predictions with 
which could then theoretically be applied in industry.
   



% =========================================================================
% MAIN NOTES:
% 
% Uvi Code doesn't have the GET function completed? Maybe it does but I don't think so.

% WHAT SECURITY ENHANCEMENTS CAN YOU MAKE TO THE PIPELINE? - MISSED FROM SHEET 4.

% Following the grade of your draft plan (88%), it's established that you need to add slightly more detail to the 
% section for each dataset, as this appeared to be the only thing that held you off of 100%.

% Pipeline plan = 20%
% Implementation & Deployment = 20%
% Application & Analysis = 20%
% Evaluation & Communication of wider issues = 20%

% All in all, it's good. While you weren't given an actual grade for the draft, she called it "very good", and there were 
% only FOUR improvements that she labelled in an entire 77-page document.

% =========================================================================
\include{AppendixA}


\printbibliography

\end{document}

