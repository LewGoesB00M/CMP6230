% -------------------------------------------------------------------------------
% Establish page structure & font.
\documentclass[12pt]{report}

\usepackage[total={6.5in, 9in},
	left=1in,
	right=1in,
	top=1in,
	bottom=1in,]{geometry} % Page structure

\usepackage{graphicx} % Required for inserting images
\graphicspath{{../../.images/}} % Any additional images I use (BCU logo, etc) are from here.

\usepackage[utf8]{inputenc} % UTF-8 encoding
\usepackage[T1]{fontenc} % T1 font
\usepackage{float}  % Allows for floats to be positioned using [H], which correctly
                    % positions them relative to their location within my LaTeX code.
\usepackage{subcaption}

% -------------------------------------------------------------------------------
% Declare biblatex with custom Harvard BCU styling for referencing.
\usepackage[
    useprefix=true,
    maxcitenames=3,
    maxbibnames=99,
    style=authoryear,
    dashed=false, 
    natbib=true,
    url=false,
    backend=biber
]{biblatex}

\usepackage[british]{babel}

% Additional styling options to ensure Harvard referencing format.
\renewbibmacro*{volume+number+eid}{
    \printfield{volume}
    \setunit*{\addnbspace}
    \printfield{number}
    \setunit{\addcomma\space}
    \printfield{eid}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

% Declaring both bib sources.
% Pipeline is the original one copied from draft pipeline, Report is new for this.
% This is because pipeline.bib is over a thousand lines long.
\addbibresource{Pipeline.bib}
\addbibresource{Report.bib}

% -------------------------------------------------------------------------------
% To prevent "Chapter N" display for each chapter
\usepackage[compact]{titlesec}
\usepackage{wasysym}
\usepackage{import}

\titlespacing*{\chapter}{0pt}{-2cm}{0.5cm}
\titleformat{\chapter}[display]
{\normalfont\bfseries}{}{0pt}{\Huge}

% -------------------------------------------------------------------------------
% Custom macro to make an un-numbered footnote.

\newcommand\blfootnote[1]{
    \begingroup
    \renewcommand\thefootnote{}\footnote{#1}
    \addtocounter{footnote}{-1}
    \endgroup
}

% -------------------------------------------------------------------------------
% Fancy headers; used to show my name, BCU logo and current chapter for the page.
\usepackage{fancyhdr}
\usepackage{calc}
\pagestyle{fancy}

\setlength\headheight{37pt} % Set custom header height to fit the image.

\renewcommand{\chaptermark}[1]{%
    \markboth{#1}{}} % Include chapter name.


% Lewis Higgins - ID 22133848           [BCU LOGO]                [CHAPTER NAME]
\lhead{Lewis Higgins - ID 22133848~~~~~~~~~~~~~~~\includegraphics[width=1.75cm]{BCU}}
\fancyhead[R]{\leftmark}

% ------------------------------------------------------------------------------
% Used to add PDF hyperlinks for figures and the contents page.

\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=black,
}

% ------------------------------------------------------------------------------
\usepackage{xcolor} 
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{amssymb}
% ------------------------------------------------------------------------------
\usepackage{tcolorbox}
\newcommand{\para}{\vspace{7pt}\noindent}
% -------------------------------------------------------------------------------

\title{Data Management and MLOps Activities Log Report}
\author{Lewis Higgins - Student ID 22133848}
\date{December 2024}

% -------------------------------------------------------------------------------

\begin{document}


\makeatletter
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.7\linewidth]{BCU}\\[4ex]
        {\huge \bfseries CMP6230 - Assignment 2}\\[2ex]
        {\large \bfseries  \@title}\\[50ex]
        {\@author}\\[2ex]
        {CMP6230 - Data Management and Machine Learning Operations}\\[2ex]
        {Module Coordinator: Sima Iranmanesh}\\[10ex]
    \end{center}
\end{titlepage}
\makeatother
\thispagestyle{empty}
\newpage


% Page counter trick so that the contents page doesn't increment it.
\setcounter{page}{0}

\tableofcontents
\thispagestyle{empty}

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
This report covers the planning and implementation of a five-stage Machine Learning Operations pipeline, from the initial 
data ingestion to the monitoring of the produced model, beginning 
with the identification of three candidate datasets for the pipeline to be conducted with, and continuing 
into descriptions of what each stage of the pipeline consists of, and how it will be implemented with the
one chosen dataset using a wide variety of software that is also used within industry. The implementation 
based on the plan produces a fully operational Machine Learning Operations (MLOps) pipeline, with a deployed model 
that can be used to make predictions via a REST API hosted on a Uvicorn server.

% Importing the sections from the original report here.
\include{Datasets.tex}
\include{PipelineStages.tex}


\chapter{Implementing the MLOps Pipeline}
\section{Ethical and Legal Considerations}
The dataset was shared under an Apache 2.0 open-source licence, permitting access and modification with no restrictions
except crediting the original author \autocite{apache_apache_nodate}, meaning that there are not any ethical or legal 
considerations of note with this dataset's usage. Given that the chosen dataset also consists of synthetic data,
there are fewer necessary considerations for its use.

\subsection{Synthetic Data}
% What is Synthetic Data and what are the common methods that are currently leveraged to attempt
% to perform Synthetic Data Generation?
\subsubsection{What is synthetic data?}
This term has been frequently used throughout the report to describe the Loan Approval Classification Dataset, and refers to 
data that has been generated algorithmically rather than collected from a real source. However, the generation of the 
synthetic data does often depend on real data to identify patterns and trends, meaning that legislation such as GDPR is still relevant
in those scenarios because the generated data must be impossible to link back to the original subject \autocite{Lopez2022OnTL}.

\subsubsection{How is synthetic data generated?}
An example of a synthetic data generation method is the Synthetic Minority Oversampling Technique, also known as SMOTE, which was used
in the generation of the loan dataset \autocite{zoppelleto_financial_nodate}, which creates synthetic data in a dataset based on the
other rows as previously mentioned in Section \ref{sec:Dataset}. It does this using the K-Nearest Neighbours algorithm to generate 
data points based on the averages across other similar points. SMOTE will also be used in Section \ref{sec:ImpPreprocessing} to balance
the dataset by oversampling the minority class (approved loans), as it was discovered in Figure \ref{fig:Bar6} that there are considerably 
more rejected loans than approved loans in this dataset.

\subsection{Model drift}
Model drift is a phenomenon that affects deployed production machine learning models where changes in 
their environment over time affects their performance \autocite{nigenda_amazon_2022}. Model drift is not an 
immediate occurrence, and can take a long time to occur, emphasising the importance of continuous model evaluation. 
Table \ref{tab:Drift} details the two primary kinds of model drift.

\pagebreak

\begin{longtable}{ | p{0.2\textwidth} | p{0.4\textwidth} | p{0.3\textwidth} |}
    \hline
    \cellcolor{blue!25}Drift type & \cellcolor{blue!25}Description & \cellcolor{blue!25}Dataset example\\
    \hline
    Data drift & Changes in the distributions of the ingested data over time that eventually significantly differ from the model's training data \autocite{datacamp_understanding_nodate}.
    & In this dataset, interest rates and people's yearly income may change as time passes or economic inflation occurs.\\
    \hline
    Concept drift & Changes in the relationship between the input and target variables \autocite{nigenda_amazon_2022}. 
    & In this dataset, this is somewhat unlikely. However, it could occur if there is a significant housing or job market crash 
    that would cause more people to need loans, which would change the original relationships between the variables.\\
    \hline
\caption{The common types of model drift.}\label{tab:Drift}
\end{longtable}

\para Model drift can be a significant issue that greatly impacts the performance of ML models if it is not quickly noticed, and can 
also be an ethical concern if the model is being used to influence decisions such as granting loans in this project. 
Therefore, combatting model drift through methods such as continuous monitoring is necessary to ensure that the model remains accurate 
and usable. This can be accomplished in this project through MLFlow's monitoring dashboard.

\subsection{Data handling}
This project must then also take into account four key elements of data handling - these being data privacy, security, 
ethics and data protection laws. 

\begin{longtable}{ | p{0.2\textwidth} | p{0.7\textwidth} |}
    \hline
    \cellcolor{blue!25}Term & \cellcolor{blue!25}Description\\
    \hline
    Data privacy & An individual's ability to govern what happens to their personal data \autocite{cloudflare_what_nodate}. Personal data 
    refers to data that could be used to singularly identify someone \autocite{yang_big_2021}.\\
    \hline
    Data security & The protection of personal/sensitive information from unauthorized access, use or manipulation \autocite{ibm_security_2021}.
    This can be the physical protection of material such as hard drives, and software protections like encryption. \\
    \hline
    Data ethics & A blanket term encompassing the moral obligations of data collection, use and protection \autocite{harvard_business_school_5_2021}.
    Ethical data storage would mean that the data subjects willingly gave their data and can ask for its deletion at any point. 
    Mandated by data protection legislation. \\
    \hline 
    Big data ethics & The application of data ethics to massive datasets, concerning the implications of their collection and use on society as a whole
    \autocite{richards_big_2014}. \\
    \hline 
    General Data \newline Protection \newline Regulations (GDPR) & Legislation introduced in the EU in 2016, giving individuals significantly more 
    rights over their personal data. Data subjects most notably may request a copy of their data, the removal of their data, and to object to their data's 
    collection \autocite{ico_guide_2024}. Additionally, data must be kept secure using all available means. Companies who fail to adhere to these policies
    face significant sanctions of \euro10,000,000 or 2\% of the company's annual turnover for minor violations, or double this (\euro20,000,000, 4\% turnover)
    for major violations, whichever figure is higher. \\
    \hline
    Data Protection Act 2018 & When the UK left the EU, the GDPR no longer applied. Therefore, the UK adopted the GDPR as an amendment to its own
    Data Protection Act. There are minimal differences between the two, only that the UK's fines are in GBP rather than Euros, meaning fines go up 
    to \pounds17,500,000 or 4\% turnover \autocite{ico_enforcement_2024}. \\
    \hline
\caption{A brief overview of relevant data terminology.}\label{tab:dataTerms}
% Maybe it shouldn't be "brief". I think GDPR especially needs its own paragraph moreso than a table column.
\end{longtable}

\noindent Because this dataset consists of entirely synthetic data, very few of these concerns apply to this pipeline. 
However, the ethics of synthetic data generation can be called into question as there are few details on the dataset's Kaggle 
page describing the source used for the generation of this data, and whether the real people that this data was created based 
on are aware of this and consented to it. Aside from this, there are no further concerns as data privacy and GDPR are not 
relevant given that the data used to train the model is not real.


% Example 2 (SimonRoadknight) is 21,334 words, or 18,809 without its appendices and references.
% Example 3 (MihaiValentin) is 12,802 words.



\include{SoftwareInit}

\section{Package imports}
Many packages need to be imported for the Airflow DAG of the pipeline to succeed. These can be found 
below, alongside descriptions in the form of Python comments, in Figures \ref{fig:PipelineDAGImports} and 
\ref{fig:PipelineFunctionsImports}. The use of these packages within pipeline functions is detailed 
in this report within the appropriate pipeline stage.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineDAGImports.png}
    \caption{The packages necessary to run the DAG itself.}
    \label{fig:PipelineDAGImports}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctionsImport.png}
    \caption{The packages necessary to run the functions within each DAG.}
    \label{fig:PipelineFunctionsImports}
\end{figure}

\section{Data Ingestion}\label{sec:ImpIngestion}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Ingestion.png}
    \caption{The code for the entire Ingestion stage.}
    \label{fig:IngestionCode}
\end{figure}

\para This code is split across four functions that are called upon within the main 
ETL function. The ETL function will call on extract\_csv to read the dataset CSV from 
the path set as DEFAULT\_PATH. After this, some data type transformations are performed 
to ensure the optimal data types are used for each column. Finally, the transformed 
DataFrame is written to the MariaDB Columnstore instance hosted in the Docker 
container at port 3306.

\para For data validation,
Conda was used to install a helper package for Airflow that adds the Great Expectations Operator.
This operator connects to the checkpoint produced in Figure \ref{fig:GXCheckpoint3} to run the saved validation 
methods on the ingested dataset without the need to declare it as a specialised Python function within 
the code. Through the use of Great Expectations, it can be confirmed that the ingested data does not differ 
from the original data and maintains its integrity.

\section{Data Preprocessing}\label{sec:ImpPreprocessing}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Preprocessing1.png}
    \caption{The secondary functions used in the main Preprocessing function.}
    \label{fig:PreprocessingCode1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Preprocessing2.png}
    \caption{The code for the main Preprocessing function.}
    \label{fig:PreprocessingCode2}
\end{figure}

\para This code forms the Data Preprocessing stage of the pipeline. Data is retrieved from the 
Columnstore and considerable outliers are removed, primarily from the Age and Income columns, 
where data can be outright false or differs enough to heavily skew the dataset and affect scaling.
After this, categorical data is encoded using label encoding and one-hot encoding where necessary.
The data is then balanced using SMOTE to resolve the significant imbalance between granted and denied loans 
before being split into training and testing sets, which are serialized and saved into Redis. The use of 
a DirectRedis connection rather than a standard Redis connection removes the need for explicit serialization, 
as it is automatically performed when "r.set()" is called. 

\section{Model Development}\label{sec:ImpDevelopment}
Internally, this section was referred to as "Training", seen in the function name and associated 
DAG task.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Training.png}
    \caption{The code for the Training function.}
    \label{fig:TrainingCode}
\end{figure}

The Training function deserializes and reads the preprocessed DataFrame from Redis via a Direct-Redis 
connection, and then scales the data using a StandardScaler from Scikit-Learn. MLFlow is started 
to begin its tracking of the model, and then the model is instantiated and trained on the preprocessed data 
using the parameters provided to the Training function. These parameters would be provided within the DAG code.
The model is then serialized using Pickle and stored into Redis, alongside the parameters for logging purposes 
and the MLFlow run ID so that the run can be resumed in the Evaluation phase.


\section{Model Evaluation}\label{sec:ImpEvaluation}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Evaluation1.png}
    \caption{eval\_metrics, which returns the evaluation metrics of a model.}
    \label{fig:Evaluation1}
\end{figure}

\para The eval\_metrics function calculates the accuracy, precision and F1 scores of the trained model 
using predefined functions that are part of Scikit-Learn. This is later used in the main Evaluation function 
to log these scores in MLFlow.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineFunctions/Evaluation2.png}
    \caption{The main Evaluation function.}
    \label{fig:Evaluation2}
\end{figure}

\para The Evaluation function retrieves the serialized model, parameters and run ID from Redis 
via a Direct-Redis connection, deserializing the model with Pickle. The testing dataset is 
retrieved and the MLFlow run is resumed to then make predictions using the model. Using the 
eval\_metrics function, the metrics obtained are output to the console (viewable via the DAG's logs page)
and also logged in the MLFlow run. The model is then saved and the MLFlow is ended, completing the pipeline.

\para MLFlow runs are all saved to the MLFlow server running on port 5000. By accessing the server through 
a web browser at localhost:5000, the dashboard can be accessed as seen in Figure \ref{fig:MLFlowDash}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Other/1.png}
    \caption{The MLFlow dashboard, showing the first produced model.}
    \label{fig:MLFlowDash}
\end{figure}

\para The first produced model can be seen on the dashboard. By going into its page, its metrics and 
parameters that were stored as part of the Evaluation function can be viewed as seen in Figure \ref{fig:MLFlowModel}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/MLFlow/Other/2.png}
    \caption{The first model's metrics and parameters.}
    \label{fig:MLFlowModel}
\end{figure}



\section{Completed Airflow DAGs}
Two DAGs were created as part of the pipeline. "DockerContainers" consists of two BashOperators 
to start the two Docker containers for MariaDB Columnstore and Redis, whereas "MLOpsPipeline" 
consists of the five tasks of the pipeline. Figure \ref{fig:DAGsList} shows the list of DAGs, 
containing only these two\footnote{Normally, Airflow includes a large list of examples, though these were 
removed by changing the configuration file located at \texttildelow/airflow/airflow.cfg.} DAGs.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/DAGs/1.png}
    \caption{The list of DAGs in Airflow.}
    \label{fig:DAGsList}
\end{figure}

Figure \ref{fig:PipelineGraphDAG} shows the completed Airflow DAG's graph view, which is a graphical 
representation of the sequence of tasks. The five tasks of the pipeline are shown, 
though deployment is not one of them, which is further explained in Section \ref{sec:ImpDeployment}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/Airflow/DAGs/PipelineGraph.png}
    \caption{The graph view of the completed MLOpsPipeline DAG.}
    \label{fig:PipelineGraphDAG}
\end{figure}

The code for the completed DAG consists of four PythonOperators, each to call the respective main 
function of each stage as detailed in their respective section, as well as a GreatExpectationsOperator 
to run data validation between ingestion and preprocessing. It also declares some variables that are passed 
to each function, which can be easily modified.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/.Code/PipelineDAG.png}
    \caption{The complete code of the MLOpsPipeline DAG.}
    \label{fig:PipelineDAGCode}
\end{figure}

\section{Model Deployment}\label{sec:ImpDeployment}
Deployment is performed separately from the rest of the stages in this pipeline, 
as it involves the hosting of a Uvicorn server on port 8000 to run the code written 
in the Model API script using FastAPI. Through running the server using the command 
"uvicorn modelAPI:main --reload" as detailed in Figure 
\ref{fig:UviStartup}, the "docs" page of FastAPI's own Swagger API can be accessed to manually perform POST 
requests to get predictions from the model. The "--reload" argument means that whenever the 
modelAPI Python file is updated, the server will automatically update it with the changes.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/Startup.png}
    \caption{Starting the Uvicorn server on port 8000.}
    \label{fig:UviStartup}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/LoadModel.png}
    \caption{Loading the pickled model to make predictions with.}
    \label{fig:UviLoadModel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.5\linewidth]{Implementation/FastAPI+Uvi/InputAndPrediction.png}
    \caption{The FastAPI classes used for input and predictions.}
    \label{fig:UviClasses}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/Code.png}
    \caption{The FastAPI endpoints for getting model predictions.}
    \label{fig:UviCode}
\end{figure}

\para The docs page generated from these endpoints is shown below in Figure \ref{fig:UviDocs}.
Using this page, inputs can be given to the model by making a POST request to its endpoint, 
which will return a prediction.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/DocsPage.png}
    \caption{The docs page for the model-API script.}
    \label{fig:UviDocs}
\end{figure}

\para POST requests can be made by clicking on the endpoint "/loan/predict/single",
followed by "Try it out" and then entering data for each row. The model will then 
interpret the data for each column and make a prediction based upon it. To test this, 
two predictions were given to the model, where one is a loan that would be rejected (Figure \ref{fig:UviTrueNegative})
and the other is a loan that would be granted (Figure \ref{fig:UviTruePositive}). 

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/TrueNegative.png}
    \caption{The response for a loan that would be rejected (loan\_status of 0).}
    \label{fig:UviTrueNegative}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/TruePositive.png}
    \caption{The response for a loan that would be granted (loan\_status of 1).}
    \label{fig:UviTruePositive}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/FastAPI+Uvi/TruePredictionsCLI.png}
    \caption{The command-line outputs of both POST requests.}
    \label{fig:UviCLI}
\end{figure}

\para Both of these inputs can be confirmed to be correctly predicted as they were actually two 
rows from the testing split of the dataset, which the model was not trained upon.

\section{Potential security enhancements}\label{sec:SecurityEnhancements}
In relation to Model Deployment, it is important to note that the use of the "docs" page is not suitable for an actual production 
environment, as it can be manipulated by threat actors to possibly give them direct access to the 
server's backend, meaning it is normally disabled. An actual production environment would link their 
model to their actual web page with forms and text entry fields to input data, though this would not 
have been feasible for this particular project due to time constraints as well as not owning a domain 
to host the site on, meaning it is restricted to only localhost.

\section{Changes over time}
During the implementation of the pipeline, the initial package used for serializing data was PyArrow.
However, as development continued, it was discovered that many of PyArrow's useful functions are now 
deprecated, and have been since 2021. This made serializing data and passing it between DAG stages considerably more difficult, 
and for this reason an alternative package was identified: Direct-Redis. Direct-Redis builds on top of the Redis 
package, but will instantly serialize and deserialize data when set() or get() is called, greatly expediting 
the process of storing data in and retrieving data from Redis stores \autocite{direct-redis_direct-redis_nodate}.
This resolved the serialization issue, meaning the pipeline worked smoothly without any errors, and also 
resulted in much cleaner and easily-readable code. An additional alternative would have been to 
use Pickle for all serialization rather than just that of the model, which would have been functionally identical.

\para Additionally, after the original draft pipeline was created, some inefficiencies were noted across the preprocessing and deployment 
stages which were later addressed.

\subsection{Preprocessing}
The encoding of the data colossally increased the dimensionality of the dataset as a by-product of one-hot encoding.
This could have been slightly reduced by instead using label encoding on the previous loan defaults column, as one-hot encoding 
created unnecessary columns for "Yes" and "No", though only one of these could ever be true at a time, meaning a simple 1 or 0
in a single column would suffice. This is shown below in Figure \ref{fig:PreprocessingCode1NEW}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Implementation/JAN 10 UPDATES/NewEncoding.png}
    \caption{The updated Encode function, which uses label encoding for previous loan defaults.}
    \label{fig:PreprocessingCode1NEW}
\end{figure}

%%%% IS THAT ENCODE SCREENSHOT UP TO DATE? IT SHOULD BE /HOME/LEWIS RATHER THAN ~

\subsection{Deployment}

There were some inefficiencies regarding accessing predictions for the model. Figure \ref{fig:UviClasses} depicts how twenty-three
columns must be entered prior to receiving a prediction. This was due to the one-hot encoding used on the dataset, though the encoding
can instead be performed within the ModelAPI script itself so that the user only needs to enter the original 13 columns of the dataset.
Furthermore, the deployment issues were not restricted to just the user's input; the data being fed to the model was not scaled,
which could have led to wildly incorrect predictions. This was remedied by saving the StandardScaler created during the Preprocessing 
and Development stages with Pickle to a file, and then deserialising it from this file in the ModelAPI script.

\para These issues caused a total rewrite of the ModelAPI script, the details of which can be found in Appendix B. The predictions 
made after these changes can be found in Figures \ref{fig:TruePositiveNew} and \ref{fig:TrueNegativeNew}. They can be confirmed to 
be correct as they are rows taken from the testing set, meaning that the model had not previously seen them. Specifically, they are 
row 1388 (Positive / Granted loan) and row 6736 (Negative / Denied loan) of the dataset.
The row numbers differ heavily because train\_test\_split shuffles the dataset as previously discussed.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/JAN 10 UPDATES/NewTruePositiveOutput.png}
    \caption{A true positive prediction made after the ModelAPI changes.}
    \label{fig:TruePositiveNew}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\linewidth]{Implementation/JAN 10 UPDATES/NewTrueNegativeOutput.png}
    \caption{A true negative prediction made after the ModelAPI changes.}
    \label{fig:TrueNegativeNew}
\end{figure}

\section{Evaluation of development challenges and future improvements}
???
% How would you improve upon the structure of the pipeline in the future, specifically in the context of 
% data security and data privacy? 
% How does your current pipeline effectively facilitate access to the ingested data by
% both people (Data Scientists, Data Engineers, Data Analysts) and software systems? (e.g.
% the pipeline)
% How does your current pipeline compare to your initial plans?
% How does your current pipeline compare to your final plan?
% Are there any discrepancies, if so why?
% How would you improve upon the structure of the pipeline in the future?

\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
The implementation of this MLOps pipeline for loan approval classification demonstrates the successful integration of various
data management and machine learning technologies to create an automated, reproducible workflow. By leveraging tools such as Docker,
Airflow, MLflow, and FastAPI, the pipeline effectively handles data ingestion, preprocessing, model development, evaluation, and 
deployment. Key achievements of this pipeline include:

\begin{itemize}
    \item Efficient data ingestion to an OLTP MariaDB Columnstore database.
    \item Data validation using Great Expectations.
    \item Robust preprocessing techniques, including outlier removal and data balancing with SMOTE.
    \item Automated Random Forest classification model training and evaluation.
    \item Continuous model tracking and versioning with MLflow.
    \item Deployment of the model as a REST API using FastAPI and Uvicorn.
\end{itemize}

The pipeline's modular structure allows for easy maintenance and scalability, as demonstrated by the changes and improvements 
made after the original draft completion of the pipeline. This therefore could enable future enhancements such as the addition 
of other classification models such as Linear or Logistic Regression in order to find the most accurate model to make predictions with 
which could then theoretically be applied in industry.
   

% =========================================================================
% MAIN NOTES:
% 
% Uvi Code doesn't have the GET function completed? Maybe it does but I don't think so.

% Misunderstanding of Label and Ordinal encoding. Pinned a bookmark to Firefox explaining the two.
% Alternatively, with one-hot encoding, just remove the Previous_loan_defaults_no column, as if that's 0, the other must be 1.

% You may have been able to label encode the whole dataset, as random forest can apparently work well with it anyway.

% Maybe transform the data within the modelAPI script so you don't need to enter 24 columns for a prediction.
% This is the primary improvement that I think is necesary.

% Remove all mention of hosting webservers (MLFlow, Uvicorn) as part of DAGs. Research has 
% shown that you wouldn't do that for exactly the reasons you previously identified in 3.11.

% You've said the docs page is a security threat. That's true, but give a source to say that if possible.
% WHAT SECURITY ENHANCEMENTS CAN YOU MAKE TO THE PIPELINE? - MISSED FROM SHEET 4.

% Following the grade of your draft plan (88%), it's established that you need to add slightly more detail to the 
% section for each dataset, as this appeared to be the only thing that held you off of 100%.

% Rewrite Section 3.11, and make it Section 3.12.
% Add a NEW Section 3.11, about how the plan differed through iterations (Dec Draft to Jan 10 final.)
% That'd be populated with everything written in these LaTeX notes, so don't delete these as you go.
% If you do, fetch them back from earlier commits to ensure you've got something to write about, as it 
% seems that the improvements are worth a decent chunk (20%) as detailed below.

% Pipeline plan = 20%
% Implementation & Deployment = 20%
% Application & Analysis = 20%
% Evaluation & Communication of wider issues = 20%

% All in all, it's good. While you weren't given an actual grade for the draft, she called it "very good", and there were 
% only FOUR improvements that she labelled in an entire 77-page document.

% =========================================================================
\include{AppendixA}


\printbibliography

\end{document}

